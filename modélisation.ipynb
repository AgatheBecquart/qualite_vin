{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRÉATION DE MODÈLES PRÉDICTIFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.read_csv(\"winequality-red.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régréssion Linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['quality'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df[\"quality\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 1 - Basique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression().fit(X_train, y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40318034127962266"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 2 - MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données de test: 0.403\n"
     ]
    }
   ],
   "source": [
    "# On cree un pipeline de proprocessing pour les variables numériques\n",
    "numeric_features = X.select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "        ('stdscaler', MinMaxScaler()),  # moyenne nulle et écart type = 1 -> Reg, SVM, PCA\n",
    "        ])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "\n",
    "# a l'aide de la classe ColumnTransformer, \n",
    "# on déclare à quelles variables on applique quel transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "#On obtient un pipeline de preprocessing qu'on peut utiliser dans un pipeline d'entainement\n",
    "linear = LinearRegression()\n",
    "\n",
    "pipe = Pipeline([\n",
    "     ('prep', preprocessor),\n",
    "     ('linear', linear)\n",
    "])\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Évaluer la performance du modèle sur les données de test\n",
    "score = pipe.score(X_test, y_test)\n",
    "print(f\"Score sur les données de test: {score:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 3 - Polynomiales Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données de test: 0.416\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# On ajoute PolynomialFeatures dans notre pipeline de prétraitement\n",
    "numeric_transformer = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "        ('stdscaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# a l'aide de la classe ColumnTransformer, \n",
    "# on déclare à quelles variables on applique quel transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#On obtient un pipeline de preprocessing qu'on peut utiliser dans un pipeline d'entainement\n",
    "linear = LinearRegression()\n",
    "\n",
    "pipe = Pipeline([\n",
    "     ('prep', preprocessor),\n",
    "     ('linear', linear)\n",
    "])\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Évaluer la performance du modèle sur les données de test\n",
    "score = pipe.score(X_test, y_test)\n",
    "print(f\"Score sur les données de test: {score:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 4 - Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données de test: 0.429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures \n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('stdscaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Utiliser ColumnTransformer pour appliquer le pré-traitement à chaque type de variable\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Définir un modèle de régression Ridge avec une valeur d'alpha de 1\n",
    "ridge = Ridge(alpha=1)\n",
    "\n",
    "# Créer un pipeline final qui applique le prétraitement et la régression Ridge\n",
    "pipe = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('ridge', ridge)\n",
    "])\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Évaluer la performance du modèle sur les données de test\n",
    "score = pipe.score(X_test, y_test)\n",
    "print(f\"Score sur les données de test: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.428863698436568\n",
      "[5.41541482 5.07852091 5.74173536 5.43982961 5.72214828 5.23009829\n",
      " 5.09225796 5.04579926 5.78637909 5.7012053  6.23566215 5.22188441\n",
      " 5.58687187 5.28959759 5.40555788 6.42345003 5.23038494 5.5615684\n",
      " 6.73772261 5.43065305 5.09189172 5.21429994 5.84146804 6.30489433\n",
      " 5.36134454 5.4566786  6.19272095 5.34547999 5.22921754 6.26688235\n",
      " 5.26691554 5.37861249 5.77253695 5.26419393 5.52914966 5.03828927\n",
      " 6.25501393 5.76283687 5.60637469 6.09386612 5.48569308 5.24774469\n",
      " 6.22548518 5.27015007 6.09153057 5.98804821 6.57659727 5.5375726\n",
      " 5.13305344 5.5658485  5.08433226 5.04152309 5.55516907 6.44850478\n",
      " 4.9608125  5.0555761  6.10473935 5.37977139 5.80797513 5.26055214\n",
      " 5.6200205  5.95251069 5.26424097 5.23982933 6.53289823 5.34238963\n",
      " 6.3808879  5.3480738  6.47007946 5.27113648 6.35538692 4.87030219\n",
      " 5.84242718 5.80371663 6.17808994 5.25965121 6.82554234 5.76267475\n",
      " 6.0814531  6.38330464 5.2979865  6.51813984 5.47423781 5.56650699\n",
      " 5.755914   6.43743109 5.28567261 5.910301   6.38184419 5.15213835\n",
      " 6.09926433 5.69178802 5.67524399 5.79500418 5.11587322 5.72897019\n",
      " 5.2291675  5.74491042 4.96428977 5.53660304 5.00979277 5.15320452\n",
      " 5.85260833 5.61171509 5.50966105 6.16064147 5.76934861 5.39632021\n",
      " 6.01734578 5.40832666 6.68477157 5.23069846 5.86474426 4.84788858\n",
      " 5.77396701 5.97145361 6.03482391 5.45869211 5.00360313 5.84365526\n",
      " 6.12380076 5.37119628 5.78057965 5.31583016 5.42390893 5.26278229\n",
      " 6.22431803 5.62510315 5.59237897 5.81875767 5.84242718 5.1654428\n",
      " 5.06371981 6.3794717  5.5658485  5.06625761 5.09105611 5.41669595\n",
      " 5.1580099  5.68409336 5.93534566 6.10379913 6.29720404 5.43604918\n",
      " 6.07902637 5.36332261 6.01499924 5.27125196 5.94535553 5.10283152\n",
      " 5.70229165 6.16094633 5.10076345 5.66495839 5.84242718 6.06521125\n",
      " 5.27625247 5.94165331 5.44933106 6.00909401 6.28070326 5.64678417\n",
      " 6.20871206 5.07982352 5.39661687 5.63272665 4.67969894 5.19270265\n",
      " 4.89214367 4.99491085 5.23061346 4.98643151 6.23511012 5.4574039\n",
      " 5.80649223 5.88495153 6.04497792 5.29117044 5.32285781 5.32533443\n",
      " 4.48918362 6.34239973 5.4999798  6.42368161 5.09665657 6.43774638\n",
      " 5.30078964 5.79805323 6.73238529 5.4574039  5.47676138 6.02783632\n",
      " 5.59074907 6.53649211 5.76642608 5.30649032 4.82510875 5.35283658\n",
      " 5.58374274 6.16064147 5.41475749 5.80834975 5.4006585  5.09487839\n",
      " 6.70275351 5.61803379 4.96374848 5.65109886 5.72426145 5.85832297\n",
      " 6.15876014 4.79582365 5.86321941 6.56611829 6.29223715 5.78089653\n",
      " 5.36738826 5.2536933  5.75714786 5.31243291 5.15649439 6.19534864\n",
      " 6.32781423 6.02547407 4.97831004 4.89180916 5.22459006 6.49620029\n",
      " 5.36323719 5.32180244 5.32205657 4.98757256 6.26950595 5.95686332\n",
      " 5.88839984 6.16064147 5.35204611 5.755914   4.86031747 5.1070085\n",
      " 5.70618367 5.00495397 5.7764665  6.2044163  5.46387957 5.54095441\n",
      " 6.23062916 5.3591519  6.77865801 5.21009448 5.72911128 5.5851857\n",
      " 5.4220193  5.52976186 5.00530655 5.19676792 5.50295123 5.79913107\n",
      " 5.74763221 6.83527211 6.22843793 5.85743763 5.29117044 6.46945964\n",
      " 6.00173416 6.40584194 5.16362747 4.95904174 5.98206349 6.37395642\n",
      " 5.23261007 5.82388893 5.38824404 5.2266806  5.38167888 5.36661782\n",
      " 5.6596152  6.2918525  6.26586043 5.30785014 6.58951078 4.9854396\n",
      " 5.41988352 5.47352835 5.41349908 5.8427772  5.09571678 6.10379913\n",
      " 5.1036545  5.70579137 5.840413   6.63574396 5.71471772 5.55120923\n",
      " 5.0511783  6.40783975 5.15867276 6.33433994 6.23271352 6.449183\n",
      " 5.46452584 5.15721093 6.22587757 5.29842714 5.25416119 5.2995478\n",
      " 5.87267056 5.91215181 5.9316914  6.62018698 5.54552189 5.56459744\n",
      " 5.47541151 5.60926069 5.26419393 5.72945072 5.31691919 5.28212353\n",
      " 6.30933085 5.12492468]\n",
      "803     6\n",
      "124     5\n",
      "350     6\n",
      "682     5\n",
      "1326    6\n",
      "       ..\n",
      "1259    6\n",
      "1295    5\n",
      "1155    5\n",
      "963     6\n",
      "704     4\n",
      "Name: quality, Length: 320, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Entrainement sur X_train\n",
    "trained_pipe = pipe.fit(X_train,y_train)\n",
    "\n",
    "# prediction sur X_test\n",
    "y_pred=trained_pipe.predict(X_test)\n",
    "\n",
    "# scoring sur X_test\n",
    "score = trained_pipe.score(X_test,y_test)\n",
    "\n",
    "print(score)\n",
    "print(y_pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('trained_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(trained_pipe, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 5 : RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données de test avec RobustScaler: 0.42260240184814746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Créer un pipeline de prétraitement pour les variables numériques avec RobustScaler\n",
    "numeric_transformer = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('robustscaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# Utiliser ColumnTransformer pour appliquer le pré-traitement à chaque type de variable\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Créer un pipeline final qui applique le prétraitement et la régression Ridge\n",
    "pipe = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('ridge', ridge)\n",
    "])\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Évaluer la performance du modèle sur les données de test\n",
    "score = pipe.score(X_test, y_test)\n",
    "print(f\"Score sur les données de test avec RobustScaler: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'knn__n_neighbors': 20, 'knn__weights': 'distance'}\n",
      "Best score: 0.41439067853705563\n",
      "Score sur les données de test: 0.490\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "# Créer un pipeline de prétraitement pour les variables numériques\n",
    "numeric_features = X.select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "numeric_transformer = Pipeline([\n",
    "    ('robustscaler', RobustScaler())\n",
    "])\n",
    "\n",
    "\n",
    "# Utiliser ColumnTransformer pour appliquer le pré-traitement à chaque type de variable\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Définir un modèle de régression Ridge avec une valeur d'alpha de 1\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Créer un pipeline final qui applique le prétraitement et la régression Ridge\n",
    "pipe = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('knn', knn)\n",
    "])\n",
    "\n",
    "# Définir les paramètres à tester\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': range(1, 21),\n",
    "    'knn__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Initialiser le GridSearchCV\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Adapter le GridSearchCV aux données d'entraînement\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs hyperparamètres et le score correspondant\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "# Utiliser les meilleurs hyperparamètres pour entraîner un nouveau modèle\n",
    "best_params = grid_search.best_params_\n",
    "knn_best = KNeighborsRegressor(n_neighbors=best_params['knn__n_neighbors'], \n",
    "                                weights=best_params['knn__weights'])\n",
    "pipe_best = Pipeline([\n",
    "     ('prep', preprocessor),\n",
    "     ('knn', knn_best)\n",
    "])\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "pipe_best.fit(X_train, y_train)\n",
    "\n",
    "# Évaluer la performance du modèle sur les données de test\n",
    "score = pipe_best.score(X_test, y_test)\n",
    "print(f\"Score sur les données de test: {score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28ff26c65758d064959116f1d9c8fbca26d00c18c6d798db5e6a86c21bd645e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
